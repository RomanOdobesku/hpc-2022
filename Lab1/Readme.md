# HPC 2022, ЛР1 MatMul, Одобеску Роман 6132
Данная ЛР посвящена реализации матричного умножения с использованием CUDA. В рамках данной ЛР также будет произведены сравнения следующих реализаций:
* на GPU (С++)
* на CPU (С++)
* на GPU через PyTorch (Python)
* на CPU через NumPy (Python)

Вся визуализация будет выполнена через Python. Данные для визуализации из C++ получаются путём копирования из вывода соответствующей ячейки.  
Работа выполнялась на Kaggle, используемая видеокарта Nvidia Tesla P100 (16Gb)

# Что распараллеливалось
Каждый элемент итоговой матрицы рассчитывается отдельной нитью

# Исходные данные
Генерируются рандомно (отдельно для С++ и Python частей)

# Интересная фишка
Помимо сравнения с алгоритмами из PyTorch и NumPy, а также 3D графиков в конце ЛР, в ней присутствует объяснение, почему в random seed часто указывают 42:
```
“All right,” said Deep Thought. “The Answer to the Great Question…”
“Yes..!”
“Of Life, the Universe and Everything…” said Deep Thought.
“Yes…!”
“Is…” said Deep Thought, and paused.
“Yes…!”
“Is…”
“Yes…!!!…?”
“Forty-two,” said Deep Thought, with infinite majesty and calm.”

―Douglas Adams, The Hitchhiker’s Guide to the Galaxy
```

# Основная часть на С++
## Общие моменты:
* Все эксперименты выполнялись с усреднением по времени. Количество запусков регулируется переменной runs в функции main (repeats в функции exp)
* Числа в матрицах генерируются рандомно с помощью функции random_fill (генерация производится на хосте)
* Время считается внутри функций cpu_matmul и gpu_matmul
  
## Основные функции:  
* ### matmul_kernel  
 * Функция-ядро для матричного перемножения на GPU, вызывается в gpu_matmul. Каждый элемент результирующей матрицы считается в отдельной нити.  
 * Аргументы:   
int* matrix_1, int* matrix_2, int* res - указатели на первый, второй перемножаемый массивы и результирующий соответственно. Эти указатели должны ссылаться на области памяти девайса.  
int A, int B, int C - размерности массивов. Первый имеет размерность A * B, второй B * C, результирующий - A * C.  
 * Что возвращает: ничего.
* ### gpu_matmul  
 * Функция для матричного перемножения на GPU. Выполняет следующие функции: выделяет и освобождает память на девайсе, пересылает данные с хоста на девайс, вызывает функцию-ядро matmul_kernel и замеряет время.  
 * Аргументы: те же, что и в matmul_kernel, но указатели должны ссылаться на область памяти хоста, а не девайса.  
 * Что возвращает: время работы перемножения (считалось с помощью clock() на хосте).
* ### cpu_matmul  
 * Функция для матричного перемножения на CPU. Реализует классический алгоритм перемножения матриц и замеряет время.    
 * Аргументы: те же, что и в matmul_kernel, но указатели должны ссылаться на область памяти хоста, а не девайса.  
 * Что возвращает: время работы перемножения (считалось с помощью cudaEventElapsedTime на девайсе).

## Вспомогательные функции:
* random_fill - заполняет матрицу случайными числами
* err_check - проверяет, чтобы cudaError_t (который возвращает большинство cuda функций) был равен cudaSuccess, в ином случае выводит ошибку, произошедшую во время выполнения той или иной функции
* equals - проверка двух матриц на равенство
* exp - повторяет умножение несколько раз (для одних и тех же входных значений матрицы несколько раз генерируются и перемножаются), затем усредняет время

# Результаты
Значения результирующих матриц совпадают. Ниже приведены замеры времени и ускорения, а также несколько скриншотов 3D графиков времени работы различных реализаций матричного перемножения.
## Численные значения
Значения замеров времени для различных реализаций для соответствующих размеров входных матриц. Dimensions 10 означает, что все три матрицы имеют размер 10×10. Последний столбец показывает ускорение GPU версии относительно CPU для языка C++.
![image](https://user-images.githubusercontent.com/60855603/203963692-bf092175-108b-48ef-9a97-521bbf94d15b.png)
## Графики
### Ускорение
![image](https://user-images.githubusercontent.com/60855603/203965730-0afe8232-f0c5-449b-99b4-ea48f9a86178.png)
### Графики времени выполнения
![image](https://user-images.githubusercontent.com/60855603/203965612-527daf28-1865-4fa7-b688-508454888f9d.png)
![image](https://user-images.githubusercontent.com/60855603/203965663-ae8308a9-130a-44b8-b113-eee27aeb9d37.png)
### 3D Графики времени выполнения
Здесь используются случайные размерности матриц, подробнее можно посмотреть в самом ноутбуке при наведении на каждую точку. A, B, C - числа, отвечающие за размерность матриц. Первая матрица имеет размерность A×B, вторая - B×C, третья - A×C
![image](https://user-images.githubusercontent.com/60855603/203965985-36bb167a-0b30-48a1-9c98-16cc48eb425e.png)
![image](https://user-images.githubusercontent.com/60855603/203966151-7986e370-aebf-4e18-8ea3-2d1d5cb1bfa1.png)
![image](https://user-images.githubusercontent.com/60855603/203966250-307258b9-2af4-46aa-840d-10825daefa83.png)
![image](https://user-images.githubusercontent.com/60855603/203966329-35295449-a59e-4eeb-b544-6d43cb201885.png)
![image](https://user-images.githubusercontent.com/60855603/203966440-78374a04-2434-4c12-a69a-7972134e95be.png)

# Вывод
Исходя из графиков, можно сделать вывод, что наиболее эффективно работает PyTorch реализация на GPU (что неудивительно, ведь при работе с нейронными сетями операция перемножения матриц встречается очень часто), на втором месте по производительности оказался самописный алгоритм на CUDA (С++), на третьем месте PyTorch (CPU), четвёртом - NumPy (CPU), и почётное пятое место достаётся классическому алгоритму на CPU (C++). Параллельные реализации на GPU особенно хорошо проявляют себя на высоких размерностях матриц, так как каждый элемент выходного массива вычисляется с помощью отдельной нити.




# HPC 2022, ЛР2 VectorSum, Одобеску Роман 6132
Данная ЛР посвящена реализации операции редукции (а именно суммирования) вектора с использованием CUDA. В рамках данной ЛР также будет произведены сравнения следующих реализаций:
* на GPU (С++)
* на CPU (С++)
* на GPU через PyTorch (Python)
* на CPU через NumPy (Python)

Вся визуализация будет выполнена через Python. Данные для визуализации из C++ получаются путём копирования из вывода соответствующей ячейки.  
Работа выполнялась на Kaggle, используемая видеокарта Nvidia Tesla P100 (16Gb)

# Что распараллеливалось
Каждый нить в блоке отвечает за суммирование двух элементов, на следующем шаге половина нитей простаивает. Шаги выполняются до тех пор, пока в блоке не останется одно число - сумма всех элементов в этом блоке. В конце получается массив размера количесвта блоков, который суммируется уже на cpu (размер маленький и нет особого смысла суммировать на gpu).

# Исходные данные
Генерируются рандомно (отдельно для С++ и Python частей)

# Интересная фишка
Помимо праллельного и последовтельного алгоритмов на C++ также к сравнению добавлены PyTorch (CPU и GPU) и NumPy (CPU).

# Результаты
Значения результирующих матриц совпадают. Ниже приведены замеры времени и ускорения.
## Таблица с численными значениями замеров времени
![image](https://user-images.githubusercontent.com/60855603/206912588-8f479cc0-7c5b-4321-8311-16d246453fff.png)
## Графики
![image](https://user-images.githubusercontent.com/60855603/206912606-9089dfd1-f6e1-4332-9953-7530ec6c78bb.png)

# Вывод
Исходя из графиков, можно сделать вывод, что наиболее эффективно работает PyTorch реализация на GPU, на втором месте по производительности оказался самописный алгоритм на CUDA (С++), на третьем месте PyTorch (CPU), четвёртом - NumPy (CPU), и почётное пятое место достаётся классическому алгоритму на CPU (C++). Параллельные реализации на GPU особенно хорошо проявляют себя на высокой размерности вектора, так как увеличивается общее число операций, которые можно распараллелить.



